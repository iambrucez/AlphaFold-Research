{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import load_data, mat2tensor, regression_loss\n",
    "from model.gcn import GCN\n",
    "from model.gat import GAT\n",
    "import numpy as np\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data\n",
    "features_list, adjM, labels, train_val_test_idx, dl = load_data('iYO844')\n",
    "features_list = [mat2tensor(features).to(device)\n",
    "                    for features in features_list]\n",
    "m_dim = features_list[1].shape[1]\n",
    "\n",
    "# Set train, val, test index\n",
    "labels = torch.FloatTensor(labels).to(device)\n",
    "train_idx = train_val_test_idx['train_idx']\n",
    "train_idx = np.sort(train_idx)\n",
    "val_idx = train_val_test_idx['val_idx']\n",
    "val_idx = np.sort(val_idx)\n",
    "test_idx = train_val_test_idx['test_idx']\n",
    "test_idx = np.sort(test_idx)\n",
    "\n",
    "# Build graph\n",
    "g = dgl.from_scipy(adjM+(adjM.T))\n",
    "g = dgl.remove_self_loop(g)\n",
    "g = dgl.add_self_loop(g)\n",
    "g = g.to(device)\n",
    "\n",
    "# Set model\n",
    "num_labels = dl.labels_train['num_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (layers): ModuleList(\n",
       "    (0): GraphConv(in=64, out=64, normalization=both, activation=<function elu at 0x7fa205772940>)\n",
       "    (1): GraphConv(in=64, out=64, normalization=both, activation=<function elu at 0x7fa205772940>)\n",
       "    (2): GraphConv(in=64, out=2, normalization=both, activation=None)\n",
       "  )\n",
       "  (e_conv): Sequential(\n",
       "    (0): Conv2dBlock(\n",
       "      (conv): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): Conv2dBlock(\n",
       "      (conv): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (2): Conv2dBlock(\n",
       "      (conv): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       "  (fc_list): ModuleList(\n",
       "    (0): Linear(in_features=625, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=129, out_features=64, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = GCN(g, m_dim, 64, num_labels, 2, F.elu, 0.1)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = net(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5051, -0.6336],\n",
       "        [ 0.9062, -1.1658],\n",
       "        [ 0.9253, -1.0670],\n",
       "        ...,\n",
       "        [-0.1441, -0.8804],\n",
       "        [-0.4972,  1.1266],\n",
       "        [-0.1885, -1.4643]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "182549613727cf12b46fcd4ad177be91d67bb597fee4891cf7931e6e0875b8f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
