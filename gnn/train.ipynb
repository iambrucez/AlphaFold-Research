{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import load_data, mat2tensor, regression_loss\n",
    "from model.gcn import GCN\n",
    "from model.gat import GAT\n",
    "import numpy as np\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data\n",
    "features_list, adjM, labels, train_val_test_idx, dl = load_data('iYO844')\n",
    "\n",
    "fea_list = list()\n",
    "for features in features_list:\n",
    "    if type(features) == np.ndarray:\n",
    "        features = mat2tensor(features).to(device)\n",
    "    elif type(features) == dict:\n",
    "        features = {k: mat2tensor(v).to(device) for k, v in features.items()}\n",
    "    fea_list.append(features)\n",
    "    \n",
    "features_list = fea_list\n",
    "\n",
    "m_dim = features_list[1].shape[1]\n",
    "\n",
    "# Set train, val, test index\n",
    "labels = torch.FloatTensor(labels).to(device)\n",
    "train_idx = train_val_test_idx['train_idx']\n",
    "train_idx = np.sort(train_idx)\n",
    "val_idx = train_val_test_idx['val_idx']\n",
    "val_idx = np.sort(val_idx)\n",
    "test_idx = train_val_test_idx['test_idx']\n",
    "test_idx = np.sort(test_idx)\n",
    "\n",
    "# Build graph\n",
    "g = dgl.from_scipy(adjM+(adjM.T))\n",
    "g = dgl.remove_self_loop(g)\n",
    "g = dgl.add_self_loop(g)\n",
    "g = g.to(device)\n",
    "\n",
    "# Set model\n",
    "num_labels = dl.labels_train['num_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 1600, 1600, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list[0]['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "import dgl.function as fn\n",
    "\n",
    "\n",
    "# (out_channels, kernel_size, stride, padding)\n",
    "enzyme_conv_archi = [\n",
    "    # input: 1600x1600x2\n",
    "    (2, 4, 4, 0),\n",
    "    # 400x400x2\n",
    "    (1, 4, 4, 0),\n",
    "    # 100x100x1\n",
    "    (1, 4, 4, 0),\n",
    "    # 25x25x1\n",
    "]\n",
    "\n",
    "\n",
    "class Conv2dBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(Conv2dBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.leakyrelu(self.batchnorm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 m_dim,\n",
    "                 num_hidden,\n",
    "                 num_labels,\n",
    "                 num_layers,\n",
    "                 activation,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.g = g\n",
    "        \n",
    "        # Enzyme feature\n",
    "        ## Conv2d layers for enzyme logits\n",
    "        self.conv2d_layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = 2\n",
    "        for x in enzyme_conv_archi:\n",
    "            self.conv2d_layers.append(Conv2dBlock(in_channels, x[0], kernel_size=x[1], stride=x[2], padding=x[3],))\n",
    "            in_channels = x[0]\n",
    "            \n",
    "        self.conv2d_layers.append(nn.Flatten(start_dim=1))\n",
    "        self.conv2d_layers.append(nn.Linear(625, 64))\n",
    "        self.dropout_conv2d = nn.Dropout(dropout)\n",
    "        \n",
    "        ## Linear layers for enzyme single\n",
    "        self.single_linear = nn.Linear(1600, 64)\n",
    "        \n",
    "        # fc layers: to make the features of all the nodes become the same dimension  \n",
    "        in_dims = [257, 257]\n",
    "        self.fc_list = nn.ModuleList(\n",
    "            [nn.Linear(in_dim, num_hidden, bias=True) for in_dim in in_dims])\n",
    "        for fc in self.fc_list:\n",
    "            nn.init.xavier_normal_(fc.weight, gain=1.414)\n",
    "        \n",
    "        # GC layers \n",
    "        self.GClayers = nn.ModuleList() \n",
    "        ## input layer\n",
    "        self.GClayers.append(\n",
    "            GraphConv(num_hidden, num_hidden, activation=activation))\n",
    "\n",
    "        ## hidden layers\n",
    "        for i in range(num_layers - 1):\n",
    "            self.GClayers.append(\n",
    "                GraphConv(num_hidden, num_hidden, activation=activation))\n",
    "\n",
    "        ## output layer\n",
    "        self.GClayers.append(GraphConv(num_hidden, num_labels))\n",
    "        self.dropout_GC = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, features_list):        \n",
    "        # 1. Enzyme feature\n",
    "        ## 1.1 logits tensor (input [384, 1600, 1600, 2])]))\n",
    "        e_feature_logits = features_list[0]['logits'].permute(0, 3, 1, 2)\n",
    "\n",
    "        for i, layer in enumerate(self.conv2d_layers):\n",
    "            e_feature_logits = self.dropout_conv2d(e_feature_logits)\n",
    "            e_feature_logits = layer(e_feature_logits)\n",
    "        # After: e_feature_logits: [384, 64]\n",
    "        print(f'e_feature_logits: {e_feature_logits.shape}')\n",
    "        \n",
    "        ## 1.2 single representation vector\n",
    "        e_feature_single = features_list[0]['single']\n",
    "        e_feature_single = self.single_linear(e_feature_single)\n",
    "        # After: e_feature_single: [384, 64]\n",
    "        print(f'e_feature_single: {e_feature_single.shape}')\n",
    "        \n",
    "        ## 1.3 concatenate logits and single\n",
    "        e_feature = torch.cat((e_feature_logits, e_feature_single), 1)\n",
    "        e_dim = e_feature.shape[1]\n",
    "        # After: e_feature: [384, 128]\n",
    "        print(f'e_feature: {e_feature.shape}')\n",
    "        \n",
    "        # 2. Pad the features of all the nodes and make them the same dimension\n",
    "        m_feature = features_list[1]\n",
    "        \n",
    "        e_feature = torch.cat((e_feature, torch.zeros((e_feature.shape[0], m_dim))), 1)  # [384, e_dim+129] i.e. [616, 257]\n",
    "        print(f'e_feature: {e_feature.shape}')\n",
    "        \n",
    "        m_feature = torch.cat((torch.zeros((m_feature.shape[0], e_dim)), m_feature), 1)  # [616, 128+m_dim] i.e. [616, 257]\n",
    "        print(f'm_feature: {m_feature.shape}')\n",
    "        \n",
    "        features_list = [e_feature, m_feature]\n",
    "        \n",
    "        h = []\n",
    "        for fc, feature in zip(self.fc_list, features_list):\n",
    "            h.append(fc(feature))\n",
    "        h = torch.cat(h, 0) # [1000, hidden_dim]\n",
    "        \n",
    "        print(f'h: {h.shape}')\n",
    "        \n",
    "        # 3. GC layers\n",
    "        for i, layer in enumerate(self.GClayers):\n",
    "            h = self.dropout_GC(h)\n",
    "            h = layer(self.g, h)\n",
    "            \n",
    "        # After: h: [1000, num_labels]\n",
    "\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(g, m_dim, 128, num_labels, 3, F.elu, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_feature_logits: torch.Size([384, 64])\n",
      "e_feature_single: torch.Size([384, 64])\n",
      "e_feature: torch.Size([384, 128])\n",
      "e_feature: torch.Size([384, 257])\n",
      "m_feature: torch.Size([616, 257])\n",
      "h: torch.Size([1000, 128])\n",
      "torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "h = net(features_list)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 1600])\n",
      "torch.Size([384, 64])\n"
     ]
    }
   ],
   "source": [
    "e_s = features_list[0]['single']\n",
    "print(e_s.shape)\n",
    "\n",
    "e_s = nn.Linear(1600, 64)(e_s)\n",
    "\n",
    "print(e_s.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 128])\n"
     ]
    }
   ],
   "source": [
    "e_feature = torch.cat((e, e_s), 1)\n",
    "e_dim = e_feature.shape[1]\n",
    "print(e_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([616, 129])\n"
     ]
    }
   ],
   "source": [
    "m_feature = features_list[1]\n",
    "print(m_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 257])\n"
     ]
    }
   ],
   "source": [
    "e_feature = torch.cat((e_feature, torch.zeros((e_feature.shape[0], m_dim))), 1)\n",
    "print(e_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([616, 257])\n"
     ]
    }
   ],
   "source": [
    "m_feature = torch.cat((torch.zeros((m_feature.shape[0], e_dim)), m_feature), 1)\n",
    "print(m_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 257])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list = [e_feature, m_feature]\n",
    "h = torch.cat(features_list, 0)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 1600, 1600, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_feature_logits = features_list[0]['logits']\n",
    "e_feature_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = Conv2dBlock(2, 2, kernel_size=4, stride=4, padding=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 2, 1600, 1600])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_feature_logits.permute(0, 3, 1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = net(e_feature_logits.permute(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 2, 400, 400])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 320000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(e, start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data\n",
    "features_list, adjM, labels, train_val_test_idx, dl = load_data('iYO844')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6357, 11.0893,  0.9175,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [14.0186, 11.7537, 13.0343,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [15.9612, 12.4831,  6.6941,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [17.3412,  9.8042,  8.6208,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 2.2316,  7.7314,  8.3776,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [13.6403, 13.3657, 12.5303,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_list = []\n",
    "\n",
    "for features in features_list:\n",
    "    if type(features) == np.ndarray:\n",
    "        features = mat2tensor(features).to(device)\n",
    "    elif type(features) == dict:\n",
    "        features = {k: mat2tensor(v).to(device) for k, v in features.items()}\n",
    "    fea_list.append(features)\n",
    "        \n",
    "fea_list[0]['single']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000010?line=0'>1</a>\u001b[0m features_list \u001b[39m=\u001b[39m [mat2tensor(features)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000010?line=1'>2</a>\u001b[0m                     \u001b[39mfor\u001b[39;00m features \u001b[39min\u001b[39;00m features_list]\n",
      "\u001b[1;32m/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb Cell 3'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000010?line=0'>1</a>\u001b[0m features_list \u001b[39m=\u001b[39m [mat2tensor(features)\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000010?line=1'>2</a>\u001b[0m                     \u001b[39mfor\u001b[39;00m features \u001b[39min\u001b[39;00m features_list]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "features_list = [mat2tensor(features).to(device)\n",
    "                    for features in features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.6357093, 11.089254 ,  0.9175112, ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [14.018574 , 11.753677 , 13.034294 , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [15.961157 , 12.483061 ,  6.694125 , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       ...,\n",
       "       [17.341208 ,  9.80417  ,  8.620768 , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [ 2.231642 ,  7.7314253,  8.377593 , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [13.640332 , 13.365712 , 12.530339 , ...,  0.       ,  0.       ,\n",
       "         0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list[0]['single']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Series)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39m# Load data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=3'>4</a>\u001b[0m features_list, adjM, labels, train_val_test_idx, dl \u001b[39m=\u001b[39m load_data(\u001b[39m'\u001b[39m\u001b[39miYO844\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=4'>5</a>\u001b[0m features_list \u001b[39m=\u001b[39m [mat2tensor(features)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=5'>6</a>\u001b[0m                     \u001b[39mfor\u001b[39;00m features \u001b[39min\u001b[39;00m features_list]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=6'>7</a>\u001b[0m m_dim \u001b[39m=\u001b[39m features_list[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39m# Set train, val, test index\u001b[39;00m\n",
      "\u001b[1;32m/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb Cell 2'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39m# Load data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=3'>4</a>\u001b[0m features_list, adjM, labels, train_val_test_idx, dl \u001b[39m=\u001b[39m load_data(\u001b[39m'\u001b[39m\u001b[39miYO844\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=4'>5</a>\u001b[0m features_list \u001b[39m=\u001b[39m [mat2tensor(features)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=5'>6</a>\u001b[0m                     \u001b[39mfor\u001b[39;00m features \u001b[39min\u001b[39;00m features_list]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=6'>7</a>\u001b[0m m_dim \u001b[39m=\u001b[39m features_list[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/train.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39m# Set train, val, test index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/utils/utils.py:68\u001b[0m, in \u001b[0;36mmat2tensor\u001b[0;34m(mat)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/utils/utils.py?line=65'>66</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m     <a href='file:///Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/utils/utils.py?line=66'>67</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m mat:\n\u001b[0;32m---> <a href='file:///Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/utils/utils.py?line=67'>68</a>\u001b[0m         result[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(mat[key])\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\n\u001b[1;32m     <a href='file:///Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/utils/utils.py?line=68'>69</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m     <a href='file:///Users/brucez/Desktop/Brucez/DKU/DKU_research/AlphaFold-Research/gnn/utils/utils.py?line=69'>70</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(mat) \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mndarray:\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Series)"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data\n",
    "features_list, adjM, labels, train_val_test_idx, dl = load_data('iYO844')\n",
    "features_list = [mat2tensor(features).to(device)\n",
    "                    for features in features_list]\n",
    "m_dim = features_list[1].shape[1]\n",
    "\n",
    "# Set train, val, test index\n",
    "labels = torch.FloatTensor(labels).to(device)\n",
    "train_idx = train_val_test_idx['train_idx']\n",
    "train_idx = np.sort(train_idx)\n",
    "val_idx = train_val_test_idx['val_idx']\n",
    "val_idx = np.sort(val_idx)\n",
    "test_idx = train_val_test_idx['test_idx']\n",
    "test_idx = np.sort(test_idx)\n",
    "\n",
    "# Build graph\n",
    "g = dgl.from_scipy(adjM+(adjM.T))\n",
    "g = dgl.remove_self_loop(g)\n",
    "g = dgl.add_self_loop(g)\n",
    "g = g.to(device)\n",
    "\n",
    "# Set model\n",
    "num_labels = dl.labels_train['num_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (layers): ModuleList(\n",
       "    (0): GraphConv(in=64, out=64, normalization=both, activation=<function elu at 0x7fa205772940>)\n",
       "    (1): GraphConv(in=64, out=64, normalization=both, activation=<function elu at 0x7fa205772940>)\n",
       "    (2): GraphConv(in=64, out=2, normalization=both, activation=None)\n",
       "  )\n",
       "  (e_conv): Sequential(\n",
       "    (0): Conv2dBlock(\n",
       "      (conv): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): Conv2dBlock(\n",
       "      (conv): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (2): Conv2dBlock(\n",
       "      (conv): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       "  (fc_list): ModuleList(\n",
       "    (0): Linear(in_features=625, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=129, out_features=64, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = GCN(g, m_dim, 64, num_labels, 2, F.elu, 0.1)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = net(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5051, -0.6336],\n",
       "        [ 0.9062, -1.1658],\n",
       "        [ 0.9253, -1.0670],\n",
       "        ...,\n",
       "        [-0.1441, -0.8804],\n",
       "        [-0.4972,  1.1266],\n",
       "        [-0.1885, -1.4643]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "182549613727cf12b46fcd4ad177be91d67bb597fee4891cf7931e6e0875b8f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
